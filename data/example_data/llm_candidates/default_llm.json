{
  "qwen2.5-7b-instruct": {
    "size": "7B",
    "feature": "Qwen2.5-7B-Instruct represents an upgraded version of the Qwen model series, featuring significantly enhanced multilingual capabilities across diverse language tasks. This improved model is competitively priced at $0.30 per million input tokens and $0.30 per million output tokens.",
    "input_price": 0.20,
    "output_price": 0.20,
    "model": "qwen/qwen2.5-7b-instruct",
    "service": "NVIDIA",
    "api_endpoint": "https://integrate.api.nvidia.com/v1"
  },
  "gemma-2-9b-it": {
    "size": "9B",
    "feature": "Gemma-2-9B-IT is a 2.9-billion parameter instruction-tuned model from Google, designed for general text processing and conversational applications. This compact yet capable model offers exceptional value with ultra-low pricing of $0.10 per million input tokens and $0.10 per million output tokens.",
    "input_price": 0.10,
    "output_price": 0.10,
    "model": "google/gemma-2-9b-it",
    "service": "NVIDIA",
    "api_endpoint": "https://integrate.api.nvidia.com/v1"
  },
  "llama-3.1-8b-instruct": {
    "size": "8B",
    "feature": "Llama-3.1-8B-Instruct is Meta's 8-billion parameter model from the advanced Llama-3 series, specifically designed for conversational AI and complex reasoning tasks. This versatile model combines strong performance with reasonable costs at $0.20 per million input tokens and $0.20 per million output tokens.",
    "input_price": 0.20,
    "output_price": 0.20,
    "model": "meta/llama-3.1-8b-instruct",
    "service": "NVIDIA",
    "api_endpoint": "https://integrate.api.nvidia.com/v1"
  },
  "llama3-chatqa-1.5-8b": {
    "size": "8B",
    "feature": "Llama3-ChatQA-1.5-8B is an NVIDIA fine-tuned 8-billion parameter model specifically optimized for question-answering and reasoning applications. This specialized model delivers enhanced performance in conversational AI scenarios at $0.20 per million input and output tokens.",
    "input_price": 0.20,
    "output_price": 0.20,
    "model": "nvidia/llama3-chatqa-1.5-8b",
    "service": "NVIDIA",
    "api_endpoint": "https://integrate.api.nvidia.com/v1"
  },
  "mistral-7b-instruct-v0.3": {
    "size": "7B",
    "feature": "Mistral-7B-Instruct-v0.3 is a fast and efficient 7-billion parameter model specifically designed for instruction-following tasks. This streamlined model provides quick response times and reliable performance at cost-effective pricing of $0.20 per million input and output tokens.",
    "input_price": 0.20,
    "output_price": 0.20,
    "model": "mistralai/mistral-7b-instruct-v0.3",
    "service": "NVIDIA",
    "api_endpoint": "https://integrate.api.nvidia.com/v1"
  },
  "llama-3.3-nemotron-super-49b-v1": {
    "size": "49B",
    "feature": "Llama-3.3-Nemotron-Super-49B-v1 is a powerful 49-billion parameter Nemotron model engineered for high-accuracy performance across demanding applications. This advanced model delivers exceptional results for complex tasks, available at $0.90 per million input and output tokens.",
    "input_price": 0.90,
    "output_price": 0.90,
    "model": "nvidia/llama-3.3-nemotron-super-49b-v1",
    "service": "NVIDIA",
    "api_endpoint": "https://integrate.api.nvidia.com/v1"
  },
  "mixtral-8x7b-instruct-v0.1": {
    "size": "45B",
    "feature": "Mixtral-8×7B-Instruct-v0.1 is a 56-billion parameter Mixture of Experts (MoE) model composed of eight 7-billion parameter expert models, specifically optimized for creative text generation. This innovative architecture provides high-quality outputs while maintaining efficiency, available at $0.60 per million input and output tokens.",
    "input_price": 0.60,
    "output_price": 0.60,
    "model": "mistralai/mixtral-8x7b-instruct-v0.1",
    "service": "NVIDIA",
    "api_endpoint": "https://integrate.api.nvidia.com/v1"
  },
  "mixtral-8x22b-instruct-v0.1": {
    "size": "141B",
    "feature": "Mixtral-8×22B-Instruct-v0.1 is an advanced 176-billion parameter Mixture of Experts model comprising eight 22-billion parameter expert components. This large-scale MoE architecture delivers exceptional performance across diverse tasks while maintaining computational efficiency, priced at $1.20 per million input and output tokens.",
    "input_price": 1.20,
    "output_price": 1.20,
    "model": "mistralai/mixtral-8x22b-instruct-v0.1",
    "service": "NVIDIA",
    "api_endpoint": "https://integrate.api.nvidia.com/v1"
  }
}