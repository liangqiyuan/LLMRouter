{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPRouter - Training\n",
    "\n",
    "This notebook demonstrates how to train the **MLPRouter** (Multi-Layer Perceptron Router).\n",
    "\n",
    "## Overview\n",
    "\n",
    "MLPRouter uses a neural network classifier with multiple hidden layers to route queries.\n",
    "\n",
    "**Key Features**:\n",
    "- Can learn complex non-linear decision boundaries\n",
    "- Flexible architecture with configurable layers\n",
    "- Good for large-scale routing problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(os.getcwd()).parent.parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "os.chdir(PROJECT_ROOT)\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmrouter.models.mlprouter import MLPRouter, MLPRouterTrainer\n",
    "from llmrouter.utils import setup_environment\n",
    "\n",
    "setup_environment()\n",
    "print(\"Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "MLPRouter uses the following configuration parameters:\n",
    "\n",
    "| Parameter | Description | Default |\n",
    "|-----------|-------------|--------|\n",
    "| `hidden_layer_sizes` | Neurons in each hidden layer | [128, 64] |\n",
    "| `activation` | Activation function | \"relu\" |\n",
    "| `solver` | Optimizer: \"adam\", \"lbfgs\", \"sgd\" | \"adam\" |\n",
    "| `alpha` | L2 regularization | 0.0001 |\n",
    "| `learning_rate` | Learning rate schedule | \"adaptive\" |\n",
    "| `max_iter` | Maximum iterations | 500 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "CONFIG_PATH = \"configs/model_config_train/mlprouter.yaml\"\n",
    "\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Current Configuration:\")\n",
    "print(\"=\" * 50)\n",
    "print(yaml.dump(config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "router = MLPRouter(yaml_path=CONFIG_PATH)\n",
    "\n",
    "print(\"Router initialized successfully!\")\n",
    "print(f\"Number of training samples: {len(router.routing_data_train)}\")\n",
    "print(f\"Number of LLM candidates: {len(router.llm_data)}\")\n",
    "print(f\"LLM candidates: {list(router.llm_data.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect MLP architecture\n",
    "print(\"MLP Model Parameters:\")\n",
    "print(router.mlp_model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MLPRouterTrainer(router=router, device='cpu')\n",
    "\n",
    "print(\"Trainer initialized!\")\n",
    "print(f\"Training samples: {len(trainer.query_embedding_list)}\")\n",
    "print(f\"Save path: {trainer.save_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmrouter.utils import load_model\n",
    "import numpy as np\n",
    "\n",
    "saved_model = load_model(trainer.save_model_path)\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "print(f\"Model type: {type(saved_model).__name__}\")\n",
    "print(f\"Number of layers: {len(saved_model.hidden_layer_sizes)}\")\n",
    "print(f\"Layer sizes: {saved_model.hidden_layer_sizes}\")\n",
    "print(f\"Classes: {saved_model.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick prediction test\n",
    "test_embedding = trainer.query_embedding_list[0].reshape(1, -1)\n",
    "prediction = saved_model.predict(test_embedding)\n",
    "\n",
    "print(f\"Test prediction: {prediction[0]}\")\n",
    "\n",
    "proba = saved_model.predict_proba(test_embedding)\n",
    "print(f\"\\nPrediction probabilities:\")\n",
    "for model, prob in zip(saved_model.classes_, proba[0]):\n",
    "    print(f\"  {model}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Learning Curve Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training loss curve\n",
    "if hasattr(saved_model, 'loss_curve_'):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(saved_model.loss_curve_)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('MLP Training Loss Curve')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Loss curve not available (model may use 'lbfgs' solver)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Architecture Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "X = np.array(trainer.query_embedding_list)\n",
    "y = np.array(trainer.model_name_list)\n",
    "\n",
    "# Test different architectures\n",
    "architectures = [\n",
    "    (64,),\n",
    "    (128,),\n",
    "    (128, 64),\n",
    "    (256, 128),\n",
    "    (256, 128, 64),\n",
    "]\n",
    "\n",
    "print(\"Architecture comparison:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "results = []\n",
    "for arch in architectures:\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=arch, max_iter=200, random_state=42)\n",
    "    scores = cross_val_score(mlp, X, y, cv=3, scoring='accuracy')\n",
    "    results.append((arch, scores.mean(), scores.std()))\n",
    "    print(f\"{str(arch):20} Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n",
    "\n",
    "best_arch, best_score, _ = max(results, key=lambda x: x[1])\n",
    "print(f\"\\nBest architecture: {best_arch} with accuracy: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "1. **Loaded Configuration**: Set up MLPRouter with YAML configuration\n",
    "2. **Trained Model**: Used MLPRouterTrainer to fit the neural network\n",
    "3. **Verified Model**: Loaded and tested the saved model\n",
    "4. **Compared Architectures**: Found optimal layer configuration\n",
    "\n",
    "**Next Steps**:\n",
    "- Use `02_mlprouter_inference.ipynb` for inference\n",
    "- Experiment with different activation functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
