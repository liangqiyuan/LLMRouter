{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Creating Custom Routers\n",
    "\n",
    "This notebook provides a comprehensive guide to creating your own custom routers in LLMRouter.\n",
    "\n",
    "## Overview\n",
    "\n",
    "LLMRouter uses a modular architecture where all routers inherit from `MetaRouter`. This design allows you to:\n",
    "\n",
    "1. **Create simple rule-based routers** (no training required)\n",
    "2. **Build ML-based routers** with custom training logic\n",
    "3. **Implement API-based routers** that use external services\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "MetaRouter (Base Class)\n",
    "    ├── route_single(query)  # Route one query\n",
    "    ├── route_batch(batch)   # Route multiple queries\n",
    "    ├── save_router(path)    # Save model state\n",
    "    └── load_router(path)    # Load model state\n",
    "\n",
    "BaseTrainer (For trainable routers)\n",
    "    ├── train()              # Training loop\n",
    "    └── loss_func()          # Loss computation\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colab\n",
    "import os\n",
    "\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    !git clone https://github.com/ulab-uiuc/LLMRouter.git\n",
    "    %cd LLMRouter\n",
    "    !pip install -e .\n",
    "    !pip install pyyaml scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(os.getcwd()).parent.parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "os.chdir(PROJECT_ROOT)\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmrouter.utils import setup_environment\n",
    "setup_environment()\n",
    "\n",
    "import json\n",
    "import yaml\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Any, Dict, List, Optional\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "print(\"Environment ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. Understanding the MetaRouter Base Class\n",
    "\n",
    "All routers must inherit from `MetaRouter` and implement two abstract methods:\n",
    "\n",
    "| Method | Description | Input | Output |\n",
    "|--------|-------------|-------|--------|\n",
    "| `route_single(query)` | Route a single query | `dict` with \"query\" key | `dict` with \"model_name\" key |\n",
    "| `route_batch(batch)` | Route multiple queries | `list` of query dicts | `list` of result dicts |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine the MetaRouter interface\n",
    "from llmrouter.models.meta_router import MetaRouter\n",
    "\n",
    "print(\"MetaRouter Abstract Methods:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"1. route_single(query: Dict) -> Dict\")\n",
    "print(\"   - Routes a single query to a model\")\n",
    "print(\"   - Must return dict with 'model_name' key\")\n",
    "print()\n",
    "print(\"2. route_batch(batch: List) -> List[Dict]\")\n",
    "print(\"   - Routes multiple queries\")\n",
    "print(\"   - Can include API calls for execution\")\n",
    "print()\n",
    "print(\"MetaRouter provides:\")\n",
    "print(\"- Automatic YAML config loading\")\n",
    "print(\"- Data loading via DataLoader\")\n",
    "print(\"- save_router() / load_router() utilities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Example 1: Simple Rule-Based Router\n",
    "\n",
    "Let's create a router that selects models based on query length.\n",
    "\n",
    "**Logic**:\n",
    "- Short queries (< 50 chars) → Small, fast model\n",
    "- Medium queries (50-200 chars) → Medium model  \n",
    "- Long queries (> 200 chars) → Large, capable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmrouter.models.meta_router import MetaRouter\n",
    "\n",
    "class QueryLengthRouter(MetaRouter):\n",
    "    \"\"\"\n",
    "    A simple router that selects models based on query length.\n",
    "    \n",
    "    No training required - pure rule-based routing.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, yaml_path: str = None, thresholds: tuple = (50, 200)):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            yaml_path: Path to YAML config (optional)\n",
    "            thresholds: (short_threshold, long_threshold) for categorizing queries\n",
    "        \"\"\"\n",
    "        # Use dummy model since no neural network is needed\n",
    "        dummy_model = nn.Identity()\n",
    "        super().__init__(model=dummy_model, yaml_path=yaml_path)\n",
    "        \n",
    "        self.short_threshold = thresholds[0]\n",
    "        self.long_threshold = thresholds[1]\n",
    "        \n",
    "        # Define model mapping (can be overridden via config)\n",
    "        self.model_mapping = {\n",
    "            \"short\": None,   # Will be set from llm_data\n",
    "            \"medium\": None,\n",
    "            \"long\": None\n",
    "        }\n",
    "        \n",
    "        # Auto-assign models based on size if llm_data is available\n",
    "        if hasattr(self, 'llm_data') and self.llm_data:\n",
    "            self._assign_models_by_size()\n",
    "        \n",
    "        print(f\"QueryLengthRouter initialized!\")\n",
    "        print(f\"  Short (<{self.short_threshold} chars): {self.model_mapping['short']}\")\n",
    "        print(f\"  Medium: {self.model_mapping['medium']}\")\n",
    "        print(f\"  Long (>{self.long_threshold} chars): {self.model_mapping['long']}\")\n",
    "    \n",
    "    def _assign_models_by_size(self):\n",
    "        \"\"\"Automatically assign models based on their size.\"\"\"\n",
    "        def parse_size(size_str):\n",
    "            try:\n",
    "                size_str = str(size_str).upper().strip()\n",
    "                if size_str.endswith('B'):\n",
    "                    return float(size_str[:-1])\n",
    "                return float(size_str)\n",
    "            except:\n",
    "                return 0.0\n",
    "        \n",
    "        # Sort models by size\n",
    "        sorted_models = sorted(\n",
    "            self.llm_data.items(),\n",
    "            key=lambda x: parse_size(x[1].get('size', '0'))\n",
    "        )\n",
    "        \n",
    "        if len(sorted_models) >= 3:\n",
    "            self.model_mapping['short'] = sorted_models[0][0]\n",
    "            self.model_mapping['medium'] = sorted_models[len(sorted_models)//2][0]\n",
    "            self.model_mapping['long'] = sorted_models[-1][0]\n",
    "        elif len(sorted_models) == 2:\n",
    "            self.model_mapping['short'] = sorted_models[0][0]\n",
    "            self.model_mapping['medium'] = sorted_models[0][0]\n",
    "            self.model_mapping['long'] = sorted_models[1][0]\n",
    "        elif len(sorted_models) == 1:\n",
    "            self.model_mapping['short'] = sorted_models[0][0]\n",
    "            self.model_mapping['medium'] = sorted_models[0][0]\n",
    "            self.model_mapping['long'] = sorted_models[0][0]\n",
    "    \n",
    "    def _categorize_query(self, query_text: str) -> str:\n",
    "        \"\"\"Categorize query by length.\"\"\"\n",
    "        length = len(query_text)\n",
    "        if length < self.short_threshold:\n",
    "            return \"short\"\n",
    "        elif length > self.long_threshold:\n",
    "            return \"long\"\n",
    "        else:\n",
    "            return \"medium\"\n",
    "    \n",
    "    def route_single(self, query: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Route a single query based on its length.\n",
    "        \n",
    "        Args:\n",
    "            query: Dict with 'query' key containing the text\n",
    "            \n",
    "        Returns:\n",
    "            Dict with original query data plus 'model_name'\n",
    "        \"\"\"\n",
    "        query_text = query.get(\"query\", \"\")\n",
    "        category = self._categorize_query(query_text)\n",
    "        model_name = self.model_mapping[category]\n",
    "        \n",
    "        result = copy.copy(query)\n",
    "        result[\"model_name\"] = model_name\n",
    "        result[\"query_category\"] = category\n",
    "        result[\"query_length\"] = len(query_text)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def route_batch(self, batch: Optional[List] = None, task_name: str = None) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Route a batch of queries.\n",
    "        \n",
    "        Args:\n",
    "            batch: List of query dicts, or None to use test data\n",
    "            task_name: Optional task name for formatting\n",
    "            \n",
    "        Returns:\n",
    "            List of results with model assignments\n",
    "        \"\"\"\n",
    "        if batch is None:\n",
    "            if hasattr(self, 'query_data_test'):\n",
    "                batch = self.query_data_test\n",
    "            else:\n",
    "                return []\n",
    "        \n",
    "        results = []\n",
    "        for query in batch:\n",
    "            if isinstance(query, dict):\n",
    "                result = self.route_single(query)\n",
    "            else:\n",
    "                result = self.route_single({\"query\": str(query)})\n",
    "            results.append(result)\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a config file for the custom router\n",
    "custom_config = {\n",
    "    \"data_path\": {\n",
    "        \"llm_data\": \"data/example_data/llm_candidates/default_llm.json\",\n",
    "        \"query_data_test\": \"data/example_data/query_data/default_query_test.jsonl\"\n",
    "    }\n",
    "}\n",
    "\n",
    "CONFIG_PATH = \"configs/model_config_train/custom_router_temp.yaml\"\n",
    "os.makedirs(os.path.dirname(CONFIG_PATH), exist_ok=True)\n",
    "\n",
    "with open(CONFIG_PATH, 'w') as f:\n",
    "    yaml.dump(custom_config, f)\n",
    "\n",
    "print(\"Config saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and test the QueryLengthRouter\n",
    "router = QueryLengthRouter(yaml_path=CONFIG_PATH)\n",
    "\n",
    "# Test queries of different lengths\n",
    "test_queries = [\n",
    "    {\"query\": \"Hi there!\"},  # Short\n",
    "    {\"query\": \"What is the capital of France and what is its population? Also tell me about its history.\"},  # Medium\n",
    "    {\"query\": \"Please provide a comprehensive analysis of the economic, political, and social factors that contributed to the Industrial Revolution in 18th century Britain, including the role of technological innovations, colonial trade, agricultural changes, and the emergence of new social classes. Compare this transformation with similar industrialization processes in other countries.\"},  # Long\n",
    "]\n",
    "\n",
    "print(\"\\nRouting Results:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    result = router.route_single(query)\n",
    "    print(f\"\\n{i}. Query ({result['query_length']} chars): {query['query'][:50]}...\")\n",
    "    print(f\"   Category: {result['query_category']}\")\n",
    "    print(f\"   Routed to: {result['model_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 4. Example 2: Keyword-Based Router\n",
    "\n",
    "A router that matches queries to models based on keyword patterns.\n",
    "\n",
    "**Use Case**: Route math questions to a math-specialized model, code questions to a coding model, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class KeywordRouter(MetaRouter):\n",
    "    \"\"\"\n",
    "    Routes queries based on keyword matching.\n",
    "    \n",
    "    Maps keyword patterns to specific models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, yaml_path: str = None, keyword_rules: dict = None):\n",
    "        dummy_model = nn.Identity()\n",
    "        super().__init__(model=dummy_model, yaml_path=yaml_path)\n",
    "        \n",
    "        # Default keyword rules (can be overridden)\n",
    "        self.keyword_rules = keyword_rules or {\n",
    "            \"math\": {\n",
    "                \"patterns\": [r\"\\bcalculate\\b\", r\"\\bsolve\\b\", r\"\\bequation\\b\", \n",
    "                            r\"\\bmath\\b\", r\"\\d+\\s*[+\\-*/]\\s*\\d+\", r\"\\bderivative\\b\",\n",
    "                            r\"\\bintegral\\b\", r\"\\bprove\\b\"],\n",
    "                \"model\": None  # Will be assigned\n",
    "            },\n",
    "            \"code\": {\n",
    "                \"patterns\": [r\"\\bcode\\b\", r\"\\bprogram\\b\", r\"\\bfunction\\b\",\n",
    "                            r\"\\bpython\\b\", r\"\\bjavascript\\b\", r\"\\bdebug\\b\",\n",
    "                            r\"\\balgorithm\\b\", r\"\\bAPI\\b\"],\n",
    "                \"model\": None\n",
    "            },\n",
    "            \"general\": {\n",
    "                \"patterns\": [],  # Fallback\n",
    "                \"model\": None\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Compile regex patterns\n",
    "        for category in self.keyword_rules:\n",
    "            patterns = self.keyword_rules[category][\"patterns\"]\n",
    "            self.keyword_rules[category][\"compiled\"] = [\n",
    "                re.compile(p, re.IGNORECASE) for p in patterns\n",
    "            ]\n",
    "        \n",
    "        # Assign models from llm_data if available\n",
    "        if hasattr(self, 'llm_data') and self.llm_data:\n",
    "            model_names = list(self.llm_data.keys())\n",
    "            # Simple assignment - you can customize this\n",
    "            for i, category in enumerate(self.keyword_rules.keys()):\n",
    "                self.keyword_rules[category][\"model\"] = model_names[i % len(model_names)]\n",
    "        \n",
    "        print(\"KeywordRouter initialized!\")\n",
    "        for cat, info in self.keyword_rules.items():\n",
    "            print(f\"  {cat}: {info['model']}\")\n",
    "    \n",
    "    def _match_category(self, query_text: str) -> str:\n",
    "        \"\"\"Match query to a category based on keywords.\"\"\"\n",
    "        for category, info in self.keyword_rules.items():\n",
    "            if category == \"general\":\n",
    "                continue\n",
    "            for pattern in info.get(\"compiled\", []):\n",
    "                if pattern.search(query_text):\n",
    "                    return category\n",
    "        return \"general\"\n",
    "    \n",
    "    def route_single(self, query: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        query_text = query.get(\"query\", \"\")\n",
    "        category = self._match_category(query_text)\n",
    "        model_name = self.keyword_rules[category][\"model\"]\n",
    "        \n",
    "        result = copy.copy(query)\n",
    "        result[\"model_name\"] = model_name\n",
    "        result[\"matched_category\"] = category\n",
    "        return result\n",
    "    \n",
    "    def route_batch(self, batch: Optional[List] = None, task_name: str = None) -> List[Dict]:\n",
    "        if batch is None:\n",
    "            batch = getattr(self, 'query_data_test', [])\n",
    "        \n",
    "        return [self.route_single(q if isinstance(q, dict) else {\"query\": str(q)}) \n",
    "                for q in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the KeywordRouter\n",
    "keyword_router = KeywordRouter(yaml_path=CONFIG_PATH)\n",
    "\n",
    "test_queries = [\n",
    "    {\"query\": \"Calculate the integral of x^2 from 0 to 5\"},\n",
    "    {\"query\": \"Write a Python function to sort a list\"},\n",
    "    {\"query\": \"What is the capital of Japan?\"},\n",
    "    {\"query\": \"Debug this JavaScript code for me\"},\n",
    "    {\"query\": \"Solve the equation 2x + 5 = 15\"},\n",
    "]\n",
    "\n",
    "print(\"\\nKeyword Routing Results:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for query in test_queries:\n",
    "    result = keyword_router.route_single(query)\n",
    "    print(f\"Query: {query['query'][:50]}...\")\n",
    "    print(f\"  Category: {result['matched_category']} -> {result['model_name']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 5. Example 3: Trainable Custom Router\n",
    "\n",
    "Now let's create a router that requires training. We'll build a simple logistic regression router.\n",
    "\n",
    "**Architecture**:\n",
    "- Extract features from query text\n",
    "- Train a classifier to predict the best model\n",
    "- Use BaseTrainer for training logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from llmrouter.models.base_trainer import BaseTrainer\n",
    "import pickle\n",
    "\n",
    "class TfidfRouter(MetaRouter):\n",
    "    \"\"\"\n",
    "    A trainable router using TF-IDF features and Logistic Regression.\n",
    "    \n",
    "    This demonstrates how to create a custom ML-based router.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, yaml_path: str):\n",
    "        dummy_model = nn.Identity()\n",
    "        super().__init__(model=dummy_model, yaml_path=yaml_path)\n",
    "        \n",
    "        # Initialize TF-IDF vectorizer\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            max_features=1000,\n",
    "            stop_words='english',\n",
    "            ngram_range=(1, 2)\n",
    "        )\n",
    "        \n",
    "        # Initialize classifier\n",
    "        self.classifier = LogisticRegression(\n",
    "            max_iter=1000,\n",
    "            multi_class='multinomial'\n",
    "        )\n",
    "        \n",
    "        # Prepare training data from routing_data_train\n",
    "        if hasattr(self, 'routing_data_train') and self.routing_data_train is not None:\n",
    "            # Get best model for each query\n",
    "            best_routes = self.routing_data_train.loc[\n",
    "                self.routing_data_train.groupby(\"query\")[\"performance\"].idxmax()\n",
    "            ].reset_index(drop=True)\n",
    "            \n",
    "            self.train_queries = best_routes[\"query\"].tolist()\n",
    "            self.train_labels = best_routes[\"model_name\"].tolist()\n",
    "            print(f\"Prepared {len(self.train_queries)} training samples\")\n",
    "        \n",
    "        self.is_trained = False\n",
    "        print(\"TfidfRouter initialized!\")\n",
    "    \n",
    "    def route_single(self, query: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        if not self.is_trained:\n",
    "            raise RuntimeError(\"Router not trained! Call trainer.train() first.\")\n",
    "        \n",
    "        query_text = query.get(\"query\", \"\")\n",
    "        \n",
    "        # Transform query to TF-IDF features\n",
    "        features = self.vectorizer.transform([query_text])\n",
    "        \n",
    "        # Predict model\n",
    "        model_name = self.classifier.predict(features)[0]\n",
    "        probabilities = self.classifier.predict_proba(features)[0]\n",
    "        confidence = max(probabilities)\n",
    "        \n",
    "        result = copy.copy(query)\n",
    "        result[\"model_name\"] = model_name\n",
    "        result[\"confidence\"] = float(confidence)\n",
    "        return result\n",
    "    \n",
    "    def route_batch(self, batch: Optional[List] = None, task_name: str = None) -> List[Dict]:\n",
    "        if batch is None:\n",
    "            batch = getattr(self, 'query_data_test', [])\n",
    "        \n",
    "        return [self.route_single(q if isinstance(q, dict) else {\"query\": str(q)}) \n",
    "                for q in batch]\n",
    "    \n",
    "    def save_model(self, path: str):\n",
    "        \"\"\"Save trained model to disk.\"\"\"\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'vectorizer': self.vectorizer,\n",
    "                'classifier': self.classifier,\n",
    "                'is_trained': self.is_trained\n",
    "            }, f)\n",
    "        print(f\"Model saved to: {path}\")\n",
    "    \n",
    "    def load_model(self, path: str):\n",
    "        \"\"\"Load trained model from disk.\"\"\"\n",
    "        with open(path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        self.vectorizer = data['vectorizer']\n",
    "        self.classifier = data['classifier']\n",
    "        self.is_trained = data['is_trained']\n",
    "        print(f\"Model loaded from: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfidfRouterTrainer(BaseTrainer):\n",
    "    \"\"\"\n",
    "    Trainer for TfidfRouter.\n",
    "    \n",
    "    Handles the training loop for the TF-IDF + LogisticRegression router.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, router: TfidfRouter, save_path: str = None):\n",
    "        super().__init__(router=router, optimizer=None, device=\"cpu\")\n",
    "        self.save_path = save_path or \"models/tfidf_router/model.pkl\"\n",
    "    \n",
    "    def train(self, dataloader=None):\n",
    "        \"\"\"Train the TF-IDF router.\"\"\"\n",
    "        print(\"Training TfidfRouter...\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Get training data from router\n",
    "        queries = self.router.train_queries\n",
    "        labels = self.router.train_labels\n",
    "        \n",
    "        print(f\"Training samples: {len(queries)}\")\n",
    "        print(f\"Unique models: {len(set(labels))}\")\n",
    "        \n",
    "        # Fit TF-IDF vectorizer\n",
    "        print(\"\\n1. Fitting TF-IDF vectorizer...\")\n",
    "        X = self.router.vectorizer.fit_transform(queries)\n",
    "        print(f\"   Feature matrix shape: {X.shape}\")\n",
    "        \n",
    "        # Train classifier\n",
    "        print(\"\\n2. Training classifier...\")\n",
    "        self.router.classifier.fit(X, labels)\n",
    "        \n",
    "        # Evaluate on training data\n",
    "        train_accuracy = self.router.classifier.score(X, labels)\n",
    "        print(f\"   Training accuracy: {train_accuracy:.4f}\")\n",
    "        \n",
    "        self.router.is_trained = True\n",
    "        \n",
    "        # Save model\n",
    "        print(f\"\\n3. Saving model...\")\n",
    "        self.router.save_model(self.save_path)\n",
    "        \n",
    "        print(\"\\nTraining complete!\")\n",
    "        return {\"train_accuracy\": train_accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create config with training data\n",
    "tfidf_config = {\n",
    "    \"data_path\": {\n",
    "        \"llm_data\": \"data/example_data/llm_candidates/default_llm.json\",\n",
    "        \"query_data_test\": \"data/example_data/query_data/default_query_test.jsonl\",\n",
    "        \"routing_data_train\": \"data/example_data/routing_data/default_routing_train_data.jsonl\",\n",
    "        \"routing_data_test\": \"data/example_data/routing_data/default_routing_test_data.jsonl\"\n",
    "    },\n",
    "    \"model_path\": {\n",
    "        \"save_model_path\": \"models/tfidf_router/model.pkl\"\n",
    "    }\n",
    "}\n",
    "\n",
    "TFIDF_CONFIG_PATH = \"configs/model_config_train/tfidf_router_temp.yaml\"\n",
    "with open(TFIDF_CONFIG_PATH, 'w') as f:\n",
    "    yaml.dump(tfidf_config, f)\n",
    "\n",
    "print(\"TF-IDF Router config saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the TfidfRouter\n",
    "tfidf_router = TfidfRouter(yaml_path=TFIDF_CONFIG_PATH)\n",
    "\n",
    "# Create trainer and train\n",
    "trainer = TfidfRouterTrainer(\n",
    "    router=tfidf_router,\n",
    "    save_path=\"models/tfidf_router/model.pkl\"\n",
    ")\n",
    "\n",
    "metrics = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained router\n",
    "test_queries = [\n",
    "    {\"query\": \"What is machine learning?\"},\n",
    "    {\"query\": \"Solve the quadratic equation x^2 - 5x + 6 = 0\"},\n",
    "    {\"query\": \"Write a function to reverse a string in Python\"},\n",
    "    {\"query\": \"Explain the theory of relativity\"},\n",
    "]\n",
    "\n",
    "print(\"\\nTF-IDF Router Results:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for query in test_queries:\n",
    "    result = tfidf_router.route_single(query)\n",
    "    print(f\"Query: {query['query'][:50]}...\")\n",
    "    print(f\"  Model: {result['model_name']}\")\n",
    "    print(f\"  Confidence: {result['confidence']:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 6. Example 4: Ensemble Router\n",
    "\n",
    "Combine multiple routing strategies for better decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class EnsembleRouter(MetaRouter):\n",
    "    \"\"\"\n",
    "    Combines multiple routers using voting.\n",
    "    \n",
    "    Each sub-router votes for a model, and the ensemble\n",
    "    selects the model with the most votes.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, routers: List[MetaRouter], weights: List[float] = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            routers: List of router instances to combine\n",
    "            weights: Optional weights for each router's vote\n",
    "        \"\"\"\n",
    "        dummy_model = nn.Identity()\n",
    "        super().__init__(model=dummy_model, yaml_path=None)\n",
    "        \n",
    "        self.routers = routers\n",
    "        self.weights = weights or [1.0] * len(routers)\n",
    "        \n",
    "        print(f\"EnsembleRouter initialized with {len(routers)} sub-routers\")\n",
    "    \n",
    "    def route_single(self, query: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        # Collect votes from all routers\n",
    "        votes = []\n",
    "        for router, weight in zip(self.routers, self.weights):\n",
    "            try:\n",
    "                result = router.route_single(query)\n",
    "                model_name = result.get(\"model_name\")\n",
    "                if model_name:\n",
    "                    votes.extend([model_name] * int(weight * 10))\n",
    "            except Exception as e:\n",
    "                print(f\"Router {type(router).__name__} failed: {e}\")\n",
    "        \n",
    "        # Count votes and select winner\n",
    "        if votes:\n",
    "            vote_counts = Counter(votes)\n",
    "            winner = vote_counts.most_common(1)[0][0]\n",
    "        else:\n",
    "            winner = \"unknown\"\n",
    "        \n",
    "        result = copy.copy(query)\n",
    "        result[\"model_name\"] = winner\n",
    "        result[\"vote_distribution\"] = dict(Counter(votes))\n",
    "        return result\n",
    "    \n",
    "    def route_batch(self, batch: Optional[List] = None, task_name: str = None) -> List[Dict]:\n",
    "        if batch is None:\n",
    "            return []\n",
    "        return [self.route_single(q if isinstance(q, dict) else {\"query\": str(q)}) \n",
    "                for q in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ensemble with QueryLengthRouter and KeywordRouter\n",
    "ensemble = EnsembleRouter(\n",
    "    routers=[router, keyword_router],  # Using previously created routers\n",
    "    weights=[1.0, 1.5]  # Give more weight to keyword router\n",
    ")\n",
    "\n",
    "test_queries = [\n",
    "    {\"query\": \"Calculate 2 + 2\"},\n",
    "    {\"query\": \"Write a comprehensive essay about the impact of artificial intelligence on modern society, including economic, social, and ethical considerations.\"},\n",
    "]\n",
    "\n",
    "print(\"\\nEnsemble Router Results:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for query in test_queries:\n",
    "    result = ensemble.route_single(query)\n",
    "    print(f\"Query: {query['query'][:60]}...\")\n",
    "    print(f\"  Winner: {result['model_name']}\")\n",
    "    print(f\"  Vote distribution: {result['vote_distribution']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## 7. Best Practices\n",
    "\n",
    "### Router Design Guidelines\n",
    "\n",
    "1. **Always inherit from MetaRouter**\n",
    "   ```python\n",
    "   class MyRouter(MetaRouter):\n",
    "       def __init__(self, yaml_path: str):\n",
    "           dummy_model = nn.Identity()  # If no neural network needed\n",
    "           super().__init__(model=dummy_model, yaml_path=yaml_path)\n",
    "   ```\n",
    "\n",
    "2. **Implement both abstract methods**\n",
    "   - `route_single()` - For single query routing\n",
    "   - `route_batch()` - For batch processing (can call route_single internally)\n",
    "\n",
    "3. **Return consistent output format**\n",
    "   ```python\n",
    "   result = copy.copy(query)  # Preserve input\n",
    "   result[\"model_name\"] = selected_model\n",
    "   return result\n",
    "   ```\n",
    "\n",
    "4. **Use YAML config for flexibility**\n",
    "   - Data paths\n",
    "   - Hyperparameters\n",
    "   - Model paths\n",
    "\n",
    "5. **Separate training logic into Trainer class**\n",
    "   - Inherit from `BaseTrainer`\n",
    "   - Implement `train()` method\n",
    "   - Keep router focused on inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for creating your own router\n",
    "ROUTER_TEMPLATE = '''\n",
    "from typing import Any, Dict, List, Optional\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "from llmrouter.models.meta_router import MetaRouter\n",
    "from llmrouter.models.base_trainer import BaseTrainer\n",
    "\n",
    "\n",
    "class MyCustomRouter(MetaRouter):\n",
    "    \"\"\"\n",
    "    Description of your router.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, yaml_path: str):\n",
    "        # Use dummy model if no neural network needed\n",
    "        dummy_model = nn.Identity()\n",
    "        super().__init__(model=dummy_model, yaml_path=yaml_path)\n",
    "        \n",
    "        # Initialize your router-specific components\n",
    "        # self.my_model = ...\n",
    "        \n",
    "        print(\"MyCustomRouter initialized!\")\n",
    "    \n",
    "    def route_single(self, query: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Route a single query.\n",
    "        \n",
    "        Args:\n",
    "            query: Dict with 'query' key\n",
    "            \n",
    "        Returns:\n",
    "            Dict with 'model_name' key added\n",
    "        \"\"\"\n",
    "        query_text = query.get(\"query\", \"\")\n",
    "        \n",
    "        # YOUR ROUTING LOGIC HERE\n",
    "        model_name = \"your_selected_model\"\n",
    "        \n",
    "        result = copy.copy(query)\n",
    "        result[\"model_name\"] = model_name\n",
    "        return result\n",
    "    \n",
    "    def route_batch(self, batch: Optional[List] = None, \n",
    "                    task_name: str = None) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Route a batch of queries.\n",
    "        \"\"\"\n",
    "        if batch is None:\n",
    "            batch = getattr(self, 'query_data_test', [])\n",
    "        \n",
    "        return [self.route_single(q if isinstance(q, dict) else {\"query\": str(q)}) \n",
    "                for q in batch]\n",
    "\n",
    "\n",
    "class MyCustomRouterTrainer(BaseTrainer):\n",
    "    \"\"\"\n",
    "    Trainer for MyCustomRouter (if training is needed).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, router: MyCustomRouter, **kwargs):\n",
    "        super().__init__(router=router, optimizer=None, device=\"cpu\")\n",
    "    \n",
    "    def train(self, dataloader=None):\n",
    "        \"\"\"\n",
    "        Training loop.\n",
    "        \"\"\"\n",
    "        print(\"Training MyCustomRouter...\")\n",
    "        \n",
    "        # YOUR TRAINING LOGIC HERE\n",
    "        \n",
    "        print(\"Training complete!\")\n",
    "        return {\"status\": \"success\"}\n",
    "'''\n",
    "\n",
    "print(ROUTER_TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## 8. File-Based Inference\n",
    "\n",
    "Load queries from a file and save results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load queries from a JSONL file\n",
    "def load_queries_from_file(file_path):\n",
    "    \"\"\"Load queries from a JSONL file.\"\"\"\n",
    "    queries = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                queries.append(json.loads(line))\n",
    "    return queries\n",
    "\n",
    "# Save results to a JSONL file\n",
    "def save_results_to_file(results, output_path):\n",
    "    \"\"\"Save routing results to a JSONL file.\"\"\"\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for result in results:\n",
    "            f.write(json.dumps(result, ensure_ascii=False) + '\\n')\n",
    "    print(f\"Results saved to: {output_path}\")\n",
    "\n",
    "# Example: Load from default query file\n",
    "QUERY_FILE = \"data/example_data/query_data/default_query_test.jsonl\"\n",
    "OUTPUT_FILE = \"outputs/custom_router_results.jsonl\"\n",
    "\n",
    "if os.path.exists(QUERY_FILE):\n",
    "    # Load queries\n",
    "    file_queries = load_queries_from_file(QUERY_FILE)\n",
    "    print(f\"Loaded {len(file_queries)} queries from: {QUERY_FILE}\")\n",
    "    \n",
    "    # Route using our custom QueryLengthRouter\n",
    "    file_results = router.route_batch(batch=file_queries[:10])\n",
    "    print(f\"Routed {len(file_results)} queries\")\n",
    "    \n",
    "    # Save results\n",
    "    save_results_to_file(file_results, OUTPUT_FILE)\n",
    "    \n",
    "    # Show sample results\n",
    "    print(f\"\\nSample results:\")\n",
    "    for i, result in enumerate(file_results[:3], 1):\n",
    "        print(f\"  {i}. {result.get('query', '')[:40]}...\")\n",
    "        print(f\"     Category: {result.get('query_category', 'N/A')}\")\n",
    "        print(f\"     Model: {result['model_name']}\")\n",
    "else:\n",
    "    print(f\"Query file not found: {QUERY_FILE}\")\n",
    "    print(\"Create a JSONL file with format: {\\\"query\\\": \\\"Your question\\\"}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated how to create custom routers:\n",
    "\n",
    "| Example | Type | Training | Use Case |\n",
    "|---------|------|----------|----------|\n",
    "| QueryLengthRouter | Rule-based | No | Simple length-based routing |\n",
    "| KeywordRouter | Rule-based | No | Domain-specific routing |\n",
    "| TfidfRouter | ML-based | Yes | Text classification routing |\n",
    "| EnsembleRouter | Hybrid | No | Combining multiple strategies |\n",
    "\n",
    "**Key Takeaways**:\n",
    "1. Inherit from `MetaRouter` for consistent interface\n",
    "2. Implement `route_single()` and `route_batch()` methods\n",
    "3. Use `BaseTrainer` for trainable routers\n",
    "4. YAML config provides flexibility\n",
    "5. Always return dict with `model_name` key\n",
    "\n",
    "**Next Steps**:\n",
    "- Experiment with different routing strategies\n",
    "- Combine with evaluation using `Evaluator`\n",
    "- Deploy your custom router in production"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
