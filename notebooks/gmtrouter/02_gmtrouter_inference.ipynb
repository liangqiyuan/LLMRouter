{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMTRouter - Inference\n",
    "\n",
    "This notebook demonstrates how to use a trained **GMTRouter** for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(os.getcwd()).parent.parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "os.chdir(PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from llmrouter.models.gmtrouter import GMTRouter\n",
    "from llmrouter.utils import setup_environment\n",
    "import yaml\n",
    "\n",
    "setup_environment()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Trained Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"configs/model_config_train/gmtrouter.yaml\"\n",
    "\n",
    "router = GMTRouter(yaml_path=CONFIG_PATH)\n",
    "print(\"Router loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Personalized Query Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-turn conversation example\n",
    "CONVERSATION = [\n",
    "    {\n",
    "        \"query\": \"What is machine learning?\",\n",
    "        \"user_id\": \"user_001\",\n",
    "        \"session_id\": \"session_001\",\n",
    "        \"turn\": 1\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Can you give me a practical example?\",\n",
    "        \"user_id\": \"user_001\",\n",
    "        \"session_id\": \"session_001\",\n",
    "        \"turn\": 2\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How do I implement this in Python?\",\n",
    "        \"user_id\": \"user_001\",\n",
    "        \"session_id\": \"session_001\",\n",
    "        \"turn\": 3\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"Multi-turn Routing Results:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for query in CONVERSATION:\n",
    "    result = router.route_single(query)\n",
    "    print(f\"Turn {query['turn']}: {query['query'][:40]}...\")\n",
    "    print(f\"   Routed to: {result['model_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Different User Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same query, different users\n",
    "query_text = \"Explain neural networks.\"\n",
    "\n",
    "users = [\"user_001\", \"user_002\", \"user_003\"]\n",
    "\n",
    "print(f\"Query: {query_text}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for user in users:\n",
    "    query = {\n",
    "        \"query\": query_text,\n",
    "        \"user_id\": user,\n",
    "        \"session_id\": f\"{user}_session\"\n",
    "    }\n",
    "    result = router.route_single(query)\n",
    "    print(f\"{user}: Routed to {result['model_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "GMTRouter provides:\n",
    "- Personalized routing based on user history\n",
    "- Multi-turn context awareness\n",
    "- Graph-based relationship modeling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
