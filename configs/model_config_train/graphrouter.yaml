# Config parameters for GraphRouter (GNN-based) training:


data_path:
  query_data_train: 'data/example_data/query_data/default_query_train.jsonl'
  query_data_test: 'data/example_data/query_data/default_query_test.jsonl'
  query_embedding_data: 'data/example_data/routing_data/query_embeddings_longformer.pt'
  routing_data_train: 'data/example_data/routing_data/default_routing_train_data.jsonl'
  routing_data_test: 'data/example_data/routing_data/default_routing_test_data.jsonl'
  llm_data: 'data/example_data/llm_candidates/default_llm.json'
  llm_embedding_data: 'data/example_data/llm_candidates/default_llm_embeddings.json'

model_path:
  ini_model_path: ''
  save_model_path: 'saved_models/graphrouter/graphrouter.pt'
  load_model_path: 'saved_models/graphrouter/graphrouter.pt'

metric:
  weights:
    performance: 1
    cost: 0
    llm_judge: 0

hparam:
  # GNN architecture
  hidden_dim: 64                  # Hidden layer dimension for GNN

  # Training parameters
  learning_rate: 0.001            # Learning rate for AdamW optimizer
  weight_decay: 0.0001            # L2 regularization weight decay
  train_epoch: 100                # Number of training epochs
  batch_size: 4                   # Number of masked samples per gradient step
  train_mask_rate: 0.3            # Rate of edges to mask during training

  # Data split
  val_split_ratio: 0.2            # Ratio of training data used for validation

  # Reproducibility
  random_state: 42                # Random seed for reproducibility




